{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3925b47d",
   "metadata": {},
   "source": [
    "# Logistic Regression on the MNIST dataset using Pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e6b5e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing basic required libraries\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388bb22d",
   "metadata": {},
   "source": [
    "We will use 60,000 images for training and validation, and 10,000 images for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50f318ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = MNIST(root='data/', download=True)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba1c170",
   "metadata": {},
   "source": [
    "Since, Pytorch only works with tensors, we need to first convert the images into pytorch tensors, torchvision.transforms.ToTensor() does just that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f9a6661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f29552b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST(root='data/', \n",
    "                train=True,\n",
    "                transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7555b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = MNIST(root='data/', train=False, transform=transforms.ToTensor())\n",
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277eaa9e",
   "metadata": {},
   "source": [
    "Out of the 60,000 images, we will use 54,000 for training and the remaining 6,000 for validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "423b6207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54000, 6000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "train_ds, val_ds = random_split(dataset, [54000, 6000])\n",
    "len(train_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec72e662",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size)\n",
    "test_loader = DataLoader(test_dataset, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5251bca1",
   "metadata": {},
   "source": [
    "Each image in the dataset is of 28\\*28 size, and we need to classify each digit into one of the ten possible classes. Ergo, our weights matrix will have the dimensions given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9dd9667",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "input_size = 28*28\n",
    "num_classes = 10\n",
    "\n",
    "# Logistic regression model\n",
    "model = nn.Linear(input_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc1e3015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "loss_fn = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21506591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    history = [] # for recording epoch-wise results\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # Training Phase \n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58585227",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_test(test_loader):\n",
    "    for batch in test_loader:\n",
    "        print(\"Test accuracy: \", model.test_performance(batch).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fd5d845",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07ae6c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader):\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ada1168",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        xb = xb.reshape(-1, 784)\n",
    "        out = self.linear(xb)\n",
    "        return out\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss, 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))\n",
    "        \n",
    "    def test_performance(self, batch):\n",
    "        images, labels = batch\n",
    "        preds = self(images)\n",
    "        return accuracy(preds, labels)\n",
    "    \n",
    "model = MnistModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73b8ed1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], val_loss: 0.8627, val_acc: 0.8277\n",
      "Epoch [1], val_loss: 0.6518, val_acc: 0.8530\n",
      "Epoch [2], val_loss: 0.5664, val_acc: 0.8641\n",
      "Epoch [3], val_loss: 0.5180, val_acc: 0.8736\n",
      "Epoch [4], val_loss: 0.4866, val_acc: 0.8790\n",
      "Epoch [5], val_loss: 0.4639, val_acc: 0.8838\n",
      "Epoch [6], val_loss: 0.4464, val_acc: 0.8867\n",
      "Epoch [7], val_loss: 0.4328, val_acc: 0.8878\n",
      "Epoch [8], val_loss: 0.4214, val_acc: 0.8910\n",
      "Epoch [9], val_loss: 0.4121, val_acc: 0.8925\n",
      "Epoch [10], val_loss: 0.4040, val_acc: 0.8937\n",
      "Epoch [11], val_loss: 0.3973, val_acc: 0.8961\n",
      "Epoch [12], val_loss: 0.3912, val_acc: 0.8964\n",
      "Epoch [13], val_loss: 0.3858, val_acc: 0.8977\n",
      "Epoch [14], val_loss: 0.3810, val_acc: 0.8986\n",
      "Epoch [15], val_loss: 0.3768, val_acc: 0.9001\n",
      "Epoch [16], val_loss: 0.3729, val_acc: 0.9014\n",
      "Epoch [17], val_loss: 0.3694, val_acc: 0.9021\n",
      "Epoch [18], val_loss: 0.3664, val_acc: 0.9014\n",
      "Epoch [19], val_loss: 0.3632, val_acc: 0.9026\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 0.8626750111579895, 'val_acc': 0.8276737928390503},\n",
       " {'val_loss': 0.6518032550811768, 'val_acc': 0.8529872298240662},\n",
       " {'val_loss': 0.566364049911499, 'val_acc': 0.8641242384910583},\n",
       " {'val_loss': 0.5179910659790039, 'val_acc': 0.873622715473175},\n",
       " {'val_loss': 0.48659783601760864, 'val_acc': 0.8789656758308411},\n",
       " {'val_loss': 0.463875412940979, 'val_acc': 0.8838098645210266},\n",
       " {'val_loss': 0.44637295603752136, 'val_acc': 0.8866593241691589},\n",
       " {'val_loss': 0.43275874853134155, 'val_acc': 0.8878229260444641},\n",
       " {'val_loss': 0.42144763469696045, 'val_acc': 0.8910049200057983},\n",
       " {'val_loss': 0.41208750009536743, 'val_acc': 0.8925247192382812},\n",
       " {'val_loss': 0.4040427505970001, 'val_acc': 0.8937119841575623},\n",
       " {'val_loss': 0.3973042070865631, 'val_acc': 0.8960866928100586},\n",
       " {'val_loss': 0.39118969440460205, 'val_acc': 0.896419107913971},\n",
       " {'val_loss': 0.38582512736320496, 'val_acc': 0.8977251052856445},\n",
       " {'val_loss': 0.3810231685638428, 'val_acc': 0.898580014705658},\n",
       " {'val_loss': 0.37682318687438965, 'val_acc': 0.9000760316848755},\n",
       " {'val_loss': 0.37285175919532776, 'val_acc': 0.9014058113098145},\n",
       " {'val_loss': 0.3694286048412323, 'val_acc': 0.9020707011222839},\n",
       " {'val_loss': 0.36642369627952576, 'val_acc': 0.9014058113098145},\n",
       " {'val_loss': 0.363226056098938, 'val_acc': 0.9025694131851196}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(20,0.01,model, train_loader,val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30cb0215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.907800018787384\n"
     ]
    }
   ],
   "source": [
    "eval_test(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a718008",
   "metadata": {},
   "source": [
    "We have achieved an accuracy of 90% on the MNIST dataset which is good enough for this simple model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
